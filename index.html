#!/usr/bin/env python3
"""
merge_csvs.py
Scan folder for YYYY-MM-DD.csv files, parse them, and produce all_data.json.

Produces structure:
{
  "latestDate": "YYYY-MM-DD",
  "songs": [{ "key":"Song|Album", "title":"Song", "album":"Album", "streams":12345, "daily":123, "growth28":12.34 }, ...],
  "albums": [{ "key":"ALBUM::AlbumTitle", "title":"AlbumTitle", "streams":..., "daily":..., "tracks": N, "growth28": ... }, ...],
  "history": { "Song|Album": [ { "date":"YYYY-MM-DD", "streams":12345, "daily": 123 }, ... ], ... },
  "totalHistory": [ { "date":"YYYY-MM-DD", "streams":12345, "daily":123 }, ... ]
}
"""
import os, csv, json, re, datetime, sys
from collections import defaultdict

CSV_PATTERN = re.compile(r'^\d{4}-\d{2}-\d{2}\.csv$')

def list_csv_dates(folder='.'):
    files = [f for f in os.listdir(folder) if CSV_PATTERN.match(f)]
    files.sort()
    return files

def parse_csv_text(path):
    rows = []
    with open(path, newline='', encoding='utf-8') as fh:
        reader = csv.DictReader(fh)
        for r in reader:
            rows.append({k.strip(): (v.strip() if v is not None else '') for k,v in r.items()})
    return rows

def safe_int(s):
    if s is None: return 0
    s = str(s).replace(',','').strip()
    try:
        return int(s) if s != '' else 0
    except:
        try: return int(float(s))
        except:
            return 0

def main(root='.'):
    csvfiles = list_csv_dates(root)
    if not csvfiles:
        print("No CSV files found in folder. Exiting.")
        sys.exit(1)

    history = defaultdict(list)
    total_history = []

    # process each CSV date (oldest -> newest)
    for fname in csvfiles:
        path = os.path.join(root, fname)
        date = fname[:-4]
        rows = parse_csv_text(path)
        daily_sum = 0
        streams_sum = 0
        for r in rows:
            title = (r.get('Song') or r.get('song') or '').strip()
            album = (r.get('Album') or r.get('album') or '').strip()
            if not title: continue
            daily = safe_int(r.get('Spotify daily') or r.get('Spotify Daily') or r.get('spotify daily'))
            total = safe_int(r.get('Spotify total') or r.get('Spotify Total') or r.get('spotify total'))
            key = f"{title}|{album}"
            history[key].append({ "date": date, "streams": total, "daily": daily })
            daily_sum += daily
            streams_sum += total
        total_history.append({ "date": date, "streams": streams_sum, "daily": daily_sum })

    # Latest date
    latest_date = csvfiles[-1][:-4]

    # build songs aggregate using latest totals (from last CSV)
    latest_rows = parse_csv_text(os.path.join(root, csvfiles[-1]))
    old_28_date = (datetime.datetime.strptime(latest_date, '%Y-%m-%d') - datetime.timedelta(days=28)).strftime('%Y-%m-%d')
    # find the CSV for old_28_date if exists
    old_28_path = os.path.join(root, f"{old_28_date}.csv")
    old_map = {}
    if os.path.exists(old_28_path):
        for r in parse_csv_text(old_28_path):
            t = (r.get('Song') or r.get('song') or '').strip()
            a = (r.get('Album') or r.get('album') or '').strip()
            if not t: continue
            old_map[f"{t}|{a}"] = safe_int(r.get('Spotify total') or r.get('Spotify Total') or r.get('spotify total'))

    songs = {}
    for r in latest_rows:
        t = (r.get('Song') or r.get('song') or '').strip()
        a = (r.get('Album') or r.get('album') or '').strip()
        if not t: continue
        total = safe_int(r.get('Spotify total') or r.get('Spotify Total') or r.get('spotify total'))
        daily = safe_int(r.get('Spotify daily') or r.get('Spotify Daily') or r.get('spotify daily'))
        key = f"{t}|{a}"
        old = old_map.get(key, 0)
        if old > 0:
            growth = ((total - old)/old)*100
        else:
            growth = 999999 if total>0 else 0
        songs[key] = { "key": key, "title": t, "album": a, "streams": total, "daily": daily, "growth28": growth }

    # build album aggregates
    album_map = {}
    for s in songs.values():
        a = s['album'] or 'Unknown'
        if a not in album_map:
            album_map[a] = { "key": f"ALBUM::{a}", "title": a, "streams":0, "daily":0, "tracks":0, "growths": [] }
        album_map[a]['streams'] += s['streams']
        album_map[a]['daily'] += s['daily']
        album_map[a]['tracks'] += 1
        if s['growth28'] != 999999:
            album_map[a]['growths'].append(s['growth28'])

    albums = []
    for a,v in album_map.items():
        avg = (sum(v['growths'])/len(v['growths'])) if v['growths'] else 0
        albums.append({ "key": v['key'], "title": v['title'], "streams": v['streams'], "daily": v['daily'], "tracks": v['tracks'], "growth28": avg })

    # prepare history: ensure sorted ascending by date
    for k in history:
        history[k] = sorted(history[k], key=lambda x: x['date'])

    total_history = sorted(total_history, key=lambda x: x['date'])

    out = {
        "latestDate": latest_date,
        "songs": list(songs.values()),
        "albums": albums,
        "history": history,
        "totalHistory": total_history
    }

    out_path = os.path.join(root, 'all_data.json')
    with open(out_path, 'w', encoding='utf-8') as fh:
        json.dump(out, fh, indent=2, ensure_ascii=False)

    print(f"✅ Wrote {out_path} — latest: {latest_date}; songs: {len(songs)}; albums: {len(albums)}; history keys: {len(history)}")

if __name__ == '__main__':
    main('.')
